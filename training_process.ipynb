{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdPMnd6H4TC9"
      },
      "source": [
        "## Main Notebook for Training and Evaluation\n",
        "\n",
        "---\n",
        "> Evangelia P. Panourgia, Master Student in Data Science, AUEB <br />\n",
        "> Department of Informatics, Athens University of Economics and Business <br />\n",
        "> eva.panourgia@aueb.gr <br/><br/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLG-gtYR4WdY"
      },
      "source": [
        "### Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVXqYy9W315W",
        "outputId": "7912e4b9-338b-483c-a3f2-d7d35367fc1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /Users/evangelia/Desktop/neo-ergasia-2/.venv/lib/python3.10/site-packages (3.9.1)\n",
            "Requirement already satisfied: optuna in /Users/evangelia/Desktop/neo-ergasia-2/.venv/lib/python3.10/site-packages (4.1.0)\n",
            "Requirement already satisfied: xgboost in /Users/evangelia/Desktop/neo-ergasia-2/.venv/lib/python3.10/site-packages (2.1.2)\n",
            "Requirement already satisfied: click in /Users/evangelia/Desktop/neo-ergasia-2/.venv/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /Users/evangelia/Desktop/neo-ergasia-2/.venv/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/evangelia/Desktop/neo-ergasia-2/.venv/lib/python3.10/site-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /Users/evangelia/Desktop/neo-ergasia-2/.venv/lib/python3.10/site-packages (from nltk) (4.67.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /Users/evangelia/Desktop/neo-ergasia-2/.venv/lib/python3.10/site-packages (from optuna) (1.14.0)\n",
            "Requirement already satisfied: colorlog in /Users/evangelia/Desktop/neo-ergasia-2/.venv/lib/python3.10/site-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /Users/evangelia/Desktop/neo-ergasia-2/.venv/lib/python3.10/site-packages (from optuna) (2.1.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/evangelia/Desktop/neo-ergasia-2/.venv/lib/python3.10/site-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /Users/evangelia/Desktop/neo-ergasia-2/.venv/lib/python3.10/site-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: PyYAML in /Users/evangelia/Desktop/neo-ergasia-2/.venv/lib/python3.10/site-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: scipy in /Users/evangelia/Desktop/neo-ergasia-2/.venv/lib/python3.10/site-packages (from xgboost) (1.14.1)\n",
            "Requirement already satisfied: Mako in /Users/evangelia/Desktop/neo-ergasia-2/.venv/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.3.6)\n",
            "Requirement already satisfied: typing-extensions>=4 in /Users/evangelia/Desktop/neo-ergasia-2/.venv/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /Users/evangelia/Desktop/neo-ergasia-2/.venv/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk optuna xgboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setting the Scene \n",
        "- We will import all the needeed libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kff0q-kP4aSb",
        "outputId": "a5f3901c-fece-4ba4-8566-837dacf11b7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/evangelia/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/evangelia/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/evangelia/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "/Users/evangelia/Desktop/neo-ergasia-2/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import string\n",
        "import random\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "import optuna\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC\n",
        "import os\n",
        "import joblib  # For saving and loading models\n",
        "from sklearn.metrics import classification_report\n",
        "from optuna import TrialPruned\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from optuna.exceptions import TrialPruned\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZRBXeeT4cpx"
      },
      "source": [
        "### Load Data \n",
        "- We will load the preprocessed data (`data_augmented__nlp_incidents_train.csv`) being pre-processed with `data augmentes` (generation of synthetic data usage synonyms) and basic nlp preprocess.\n",
        "- Furthermore, we will load the unlabeleed data of the competition in ordeer to predict them (`incidents.csv`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "ZAixGceaNXN9",
        "outputId": "3e820194-b218-4f02-e5e1-76c55f53b64f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>country</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1994</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>us</td>\n",
              "      <td>Recall Notification: FSIS-017-94</td>\n",
              "      <td>Case Number: 017-94   \\n            Date Opene...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1994</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>us</td>\n",
              "      <td>Recall Notification: FSIS-048-94</td>\n",
              "      <td>Case Number: 048-94   \\n            Date Opene...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1995</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>us</td>\n",
              "      <td>Recall Notification: FSIS-032-95</td>\n",
              "      <td>Case Number: 032-95   \\n            Date Opene...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1998</td>\n",
              "      <td>7</td>\n",
              "      <td>16</td>\n",
              "      <td>ca</td>\n",
              "      <td>Archive - ALLERGY ALERT -- PRESENCE OF UNDECLA...</td>\n",
              "      <td>PRESENCE OF UNDECLARED NUTS IN ORIGINALE AUGUS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1998</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>us</td>\n",
              "      <td>Recall Notification: FSIS-018-98</td>\n",
              "      <td>Case Number: 018-98  Recall Notification Repor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>560</th>\n",
              "      <td>2022</td>\n",
              "      <td>6</td>\n",
              "      <td>29</td>\n",
              "      <td>au</td>\n",
              "      <td>The Fresh Salad Co Thai Coconut Wild Rice Prep...</td>\n",
              "      <td>Page Content ​ ​​​​                 ​Date publ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>561</th>\n",
              "      <td>2022</td>\n",
              "      <td>7</td>\n",
              "      <td>18</td>\n",
              "      <td>au</td>\n",
              "      <td>Powered by Plants Pty Ltd — Cleanfit Plant Pro...</td>\n",
              "      <td>PRA number 2022/19525 Published date 18 Jul 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562</th>\n",
              "      <td>2022</td>\n",
              "      <td>7</td>\n",
              "      <td>20</td>\n",
              "      <td>ca</td>\n",
              "      <td>Certain Enjoy Life brand Soft Baked Cookies – ...</td>\n",
              "      <td>Food recall warning Certain Enjoy Life brand S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563</th>\n",
              "      <td>2022</td>\n",
              "      <td>7</td>\n",
              "      <td>28</td>\n",
              "      <td>hk</td>\n",
              "      <td>Imported biscuit may contain allergen (peanuts)</td>\n",
              "      <td>Imported biscuit may contain allergen (peanuts...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>2022</td>\n",
              "      <td>7</td>\n",
              "      <td>28</td>\n",
              "      <td>us</td>\n",
              "      <td>Wilbur’s of Maine Chocolate Confections Issues...</td>\n",
              "      <td>Wilbur’s of Maine Chocolate Confections of Fre...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>565 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     year  month  day country  \\\n",
              "0    1994      5    5      us   \n",
              "1    1994      5   12      us   \n",
              "2    1995      4   16      us   \n",
              "3    1998      7   16      ca   \n",
              "4    1998      8    6      us   \n",
              "..    ...    ...  ...     ...   \n",
              "560  2022      6   29      au   \n",
              "561  2022      7   18      au   \n",
              "562  2022      7   20      ca   \n",
              "563  2022      7   28      hk   \n",
              "564  2022      7   28      us   \n",
              "\n",
              "                                                 title  \\\n",
              "0                     Recall Notification: FSIS-017-94   \n",
              "1                     Recall Notification: FSIS-048-94   \n",
              "2                     Recall Notification: FSIS-032-95   \n",
              "3    Archive - ALLERGY ALERT -- PRESENCE OF UNDECLA...   \n",
              "4                     Recall Notification: FSIS-018-98   \n",
              "..                                                 ...   \n",
              "560  The Fresh Salad Co Thai Coconut Wild Rice Prep...   \n",
              "561  Powered by Plants Pty Ltd — Cleanfit Plant Pro...   \n",
              "562  Certain Enjoy Life brand Soft Baked Cookies – ...   \n",
              "563    Imported biscuit may contain allergen (peanuts)   \n",
              "564  Wilbur’s of Maine Chocolate Confections Issues...   \n",
              "\n",
              "                                                  text  \n",
              "0    Case Number: 017-94   \\n            Date Opene...  \n",
              "1    Case Number: 048-94   \\n            Date Opene...  \n",
              "2    Case Number: 032-95   \\n            Date Opene...  \n",
              "3    PRESENCE OF UNDECLARED NUTS IN ORIGINALE AUGUS...  \n",
              "4    Case Number: 018-98  Recall Notification Repor...  \n",
              "..                                                 ...  \n",
              "560  Page Content ​ ​​​​                 ​Date publ...  \n",
              "561  PRA number 2022/19525 Published date 18 Jul 20...  \n",
              "562  Food recall warning Certain Enjoy Life brand S...  \n",
              "563  Imported biscuit may contain allergen (peanuts...  \n",
              "564  Wilbur’s of Maine Chocolate Confections of Fre...  \n",
              "\n",
              "[565 rows x 6 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_augmented= pd.read_csv('data/data_augmented__nlp_incidents_train.csv') # load data after data augmentation\n",
        "testset_competition = pd.read_csv('data/incidents.csv', index_col=0) # load testing data (conception phase, unlabeled):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "K50gbgAy4quC",
        "outputId": "f1a9e76e-6168-49b4-ab10-df536edc69b1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>hazard-category</th>\n",
              "      <th>product-category</th>\n",
              "      <th>hazard</th>\n",
              "      <th>product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>recal notif fsis-024-94</td>\n",
              "      <td>case number 024-94 date open 07/01/1994 date c...</td>\n",
              "      <td>biological</td>\n",
              "      <td>meat, egg and dairy products</td>\n",
              "      <td>listeria monocytogenes</td>\n",
              "      <td>smoked sausage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>recal notif fsis-033-94</td>\n",
              "      <td>case number 033-94 date open 10/03/1994 date c...</td>\n",
              "      <td>biological</td>\n",
              "      <td>meat, egg and dairy products</td>\n",
              "      <td>listeria spp</td>\n",
              "      <td>sausage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>recal notif fsis-014-94</td>\n",
              "      <td>case number 014-94 date open 03/28/1994 date c...</td>\n",
              "      <td>biological</td>\n",
              "      <td>meat, egg and dairy products</td>\n",
              "      <td>listeria monocytogenes</td>\n",
              "      <td>ham slices</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>recal notif fsis-009-94</td>\n",
              "      <td>case number 009-94 date open 03/04/1994 date c...</td>\n",
              "      <td>foreign bodies</td>\n",
              "      <td>meat, egg and dairy products</td>\n",
              "      <td>plastic fragment</td>\n",
              "      <td>thermal processed pork meat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>recal notif fsis-001-94</td>\n",
              "      <td>case number 001-94 date open 01/07/1994 date c...</td>\n",
              "      <td>foreign bodies</td>\n",
              "      <td>meat, egg and dairy products</td>\n",
              "      <td>plastic fragment</td>\n",
              "      <td>chicken breast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13594</th>\n",
              "      <td>cf barrack world eat_up genial transfus dome i...</td>\n",
              "      <td>atomic_number_98 root_on world devour varieti ...</td>\n",
              "      <td>chemical</td>\n",
              "      <td>other food product / mixed</td>\n",
              "      <td>unauthorised substance ethylene oxide</td>\n",
              "      <td>ramen noodles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13595</th>\n",
              "      <td>inspir public non take_in varieti cup attic sp...</td>\n",
              "      <td>cf itch world eat_up genial transfus bean impo...</td>\n",
              "      <td>chemical</td>\n",
              "      <td>other food product / mixed</td>\n",
              "      <td>unauthorised substance ethylene oxide</td>\n",
              "      <td>ramen noodles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13596</th>\n",
              "      <td>cystic_fibrosi inspir world non wast sort tran...</td>\n",
              "      <td>pancreatic_fibrosi pep_up populac go_through s...</td>\n",
              "      <td>chemical</td>\n",
              "      <td>other food product / mixed</td>\n",
              "      <td>unauthorised substance ethylene oxide</td>\n",
              "      <td>ramen noodles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13597</th>\n",
              "      <td>cystic_fibrosi urg world non ware varieti cup ...</td>\n",
              "      <td>fibrocystic_disease_of_the_pancrea urg populac...</td>\n",
              "      <td>chemical</td>\n",
              "      <td>other food product / mixed</td>\n",
              "      <td>unauthorised substance ethylene oxide</td>\n",
              "      <td>ramen noodles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13598</th>\n",
              "      <td>mucoviscidosi recommend populac eat_up toler l...</td>\n",
              "      <td>cf root_on world non toler transfus noggin spe...</td>\n",
              "      <td>chemical</td>\n",
              "      <td>other food product / mixed</td>\n",
              "      <td>unauthorised substance ethylene oxide</td>\n",
              "      <td>ramen noodles</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13599 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title  \\\n",
              "0                                recal notif fsis-024-94   \n",
              "1                                recal notif fsis-033-94   \n",
              "2                                recal notif fsis-014-94   \n",
              "3                                recal notif fsis-009-94   \n",
              "4                                recal notif fsis-001-94   \n",
              "...                                                  ...   \n",
              "13594  cf barrack world eat_up genial transfus dome i...   \n",
              "13595  inspir public non take_in varieti cup attic sp...   \n",
              "13596  cystic_fibrosi inspir world non wast sort tran...   \n",
              "13597  cystic_fibrosi urg world non ware varieti cup ...   \n",
              "13598  mucoviscidosi recommend populac eat_up toler l...   \n",
              "\n",
              "                                                    text hazard-category  \\\n",
              "0      case number 024-94 date open 07/01/1994 date c...      biological   \n",
              "1      case number 033-94 date open 10/03/1994 date c...      biological   \n",
              "2      case number 014-94 date open 03/28/1994 date c...      biological   \n",
              "3      case number 009-94 date open 03/04/1994 date c...  foreign bodies   \n",
              "4      case number 001-94 date open 01/07/1994 date c...  foreign bodies   \n",
              "...                                                  ...             ...   \n",
              "13594  atomic_number_98 root_on world devour varieti ...        chemical   \n",
              "13595  cf itch world eat_up genial transfus bean impo...        chemical   \n",
              "13596  pancreatic_fibrosi pep_up populac go_through s...        chemical   \n",
              "13597  fibrocystic_disease_of_the_pancrea urg populac...        chemical   \n",
              "13598  cf root_on world non toler transfus noggin spe...        chemical   \n",
              "\n",
              "                   product-category                                 hazard  \\\n",
              "0      meat, egg and dairy products                 listeria monocytogenes   \n",
              "1      meat, egg and dairy products                           listeria spp   \n",
              "2      meat, egg and dairy products                 listeria monocytogenes   \n",
              "3      meat, egg and dairy products                       plastic fragment   \n",
              "4      meat, egg and dairy products                       plastic fragment   \n",
              "...                             ...                                    ...   \n",
              "13594    other food product / mixed  unauthorised substance ethylene oxide   \n",
              "13595    other food product / mixed  unauthorised substance ethylene oxide   \n",
              "13596    other food product / mixed  unauthorised substance ethylene oxide   \n",
              "13597    other food product / mixed  unauthorised substance ethylene oxide   \n",
              "13598    other food product / mixed  unauthorised substance ethylene oxide   \n",
              "\n",
              "                           product  \n",
              "0                   smoked sausage  \n",
              "1                          sausage  \n",
              "2                       ham slices  \n",
              "3      thermal processed pork meat  \n",
              "4                   chicken breast  \n",
              "...                            ...  \n",
              "13594                ramen noodles  \n",
              "13595                ramen noodles  \n",
              "13596                ramen noodles  \n",
              "13597                ramen noodles  \n",
              "13598                ramen noodles  \n",
              "\n",
              "[13599 rows x 6 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_augmented = df_augmented[['title','text','hazard-category','product-category','hazard','product']]\n",
        "df_augmented.head(3) # preview preproccessed data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "testset_competition.head(3)# preview test data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2emcuZp5G7Q"
      },
      "source": [
        "## Benchmarks Analysis \n",
        "- Benchmark analysis is crucial for evaluating classification performance in multiclass imbalance settings because it provides reference points for how well your model is performing relative to simple baseline classifiers. The `Random Classifier` and `Majority Classifier` are commonly used as benchmarks for the following reasons:\n",
        "\n",
        "### Random Classifier \n",
        "- A Random Classifier predicts class labels randomly, with **uniform** based on the distribution of classes. It sets a minimal baseline and helps understand:\n",
        "\n",
        "- `Baseline Performance`: This represents the expected performance `without learning from the data`. `If a model performs worse than a random classifier, it indicates either issues in the model or unsuitable features`.\n",
        "\n",
        "- `Chance Levels`: It shows what performance you'd `get by chance alone`, especially useful for imbalanced datasets where metrics like accuracy can be misleading.\n",
        "\n",
        "\n",
        "### Majority Classifier\n",
        "\n",
        "- A Majority Classifier always **predicts the majority class** (`the class with the highest frequency in the training data`). \n",
        "\n",
        "- It helps understand:\n",
        "\n",
        "    - `Handling Imbalance`: In multiclass imbalanced datasets, accuracy can be dominated by the majority class. The majority classifier provides a baseline to compare how well your model captures minority classes.\n",
        "    - `Baseline of Naïve Solutions`: The majority classifier reflects the simplest possible rule for prediction. If a model's performance is close to that of a majority classifier, it suggests the model is failing to generalize or adapt to the minority classes.\n",
        "    - `Focus on Class Imbalance`: Metrics like weighted accuracy, balanced accuracy, or macro-F1 score should be significantly better than those achieved by the majority classifier to indicate that a model is addressing imbalance effectively.\n",
        "\n",
        "- Note in the following code cell I implement the code for Random and Majority Classifier, in order to have a high level of \"logic\" we added the split steps of trainingtest set, but for example for the Random Classifier it is useless as it is not affected from the input, dont learn from data.\n",
        "    - Hoever, this \"skeleton\" is useful for the reamaining algorythms to buils in (both traditional and advanced) \n",
        "\n",
        "- More specifically, \n",
        "\n",
        "    - Random Classifier  Effect of X: The X values (features) **do not influence the random classifier's predictions**. It does not learn from the data in the feature column. Its predictions are purely random, so changing X will not alter its performance.\n",
        "    - Majority Classifier Effect of X: The feature column X is ignored by the majority classifier, as it does not use features for prediction. Instead, it looks only at the distribution of y in the training data.\n",
        "\n",
        "### Regarding the Implementation \n",
        "- The `DummyClassifier in scikit-learn` is a baseline model designed to evaluate classification algorithms by comparing them against simplistic strategies. These strategies provide minimal logic to make predictions and are often used as benchmarks to understand how well a more complex model performs.\n",
        "    - `strategy=\"uniform\"` (for Random Classifier): \n",
        "        - Predicts a class randomly and uniformly across all possible classes.\n",
        "        - Each class has an equal probability of being selected, irrespective of the class distribution in the training data.\n",
        "        - Use Case: Ideal for scenarios where you want to simulate random guessing.\n",
        "    - `strategy=\"most_frequent\"` (for Majoriry Classification)\n",
        "        - Always predicts the most frequent class observed in the training data.\n",
        "        - Ignores the input features entirely and focuses only on the training set's class distribution.\n",
        "        - Use Case: Useful for understanding how well a naive baseline would perform if you simply predicted the majority class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating for label: hazard-category\n",
            "F1 Score for Random Classifier (hazard-category): 0.076\n",
            "F1 Score for Majority Classifier (hazard-category): 0.047\n",
            "Evaluating for label: product-category\n",
            "F1 Score for Random Classifier (product-category): 0.034\n",
            "F1 Score for Majority Classifier (product-category): 0.019\n",
            "Evaluating for label: hazard\n",
            "F1 Score for Random Classifier (hazard): 0.005\n",
            "F1 Score for Majority Classifier (hazard): 0.001\n",
            "Evaluating for label: product\n",
            "F1 Score for Random Classifier (product): 0.000\n",
            "F1 Score for Majority Classifier (product): 0.000\n",
            "Score Sub-Task 1 - Random Classifier: 0.057\n",
            "Score Sub-Task 2 - Random Classifier: 0.003\n",
            "Score Sub-Task 1 - Majority Classifier: 0.031\n",
            "Score Sub-Task 2 - Majority Classifier: 0.001\n"
          ]
        }
      ],
      "source": [
        "def evaluate_baselines(dataframe, feature_column):\n",
        "    \"\"\"\n",
        "    Function to evaluate random and majority classifiers on a given dataframe.\n",
        "\n",
        "    Args:\n",
        "        dataframe: The input dataframe containing the dataset.\n",
        "        feature_column: The name of the column in the dataframe to be used as features.\n",
        "    \"\"\"\n",
        "    np.random.seed(42)  # For reproducibility\n",
        "\n",
        "    # Train-test split with optional stratification\n",
        "    trainset, testset = train_test_split(\n",
        "        dataframe, \n",
        "        test_size=0.2, \n",
        "        random_state=2024, \n",
        "        # \"skeleton\" for the main algo here add stratisfy to hold proportion of classes \n",
        "    )\n",
        "   \n",
        "    # Random and Majority classifiers for each label\n",
        "    for label in ('hazard-category', 'product-category', 'hazard', 'product'):\n",
        "        print(f\"Evaluating for label: {label}\")\n",
        "\n",
        "        # Features and target\n",
        "        X_train = trainset[feature_column]\n",
        "        y_train = trainset[label]\n",
        "        X_test = testset[feature_column]\n",
        "        y_test = testset[label]\n",
        "\n",
        "        # Random Classifier\n",
        "        random_clf = DummyClassifier(strategy=\"uniform\", random_state=2024)\n",
        "        random_clf.fit(X_train, y_train) # it is uselless X stimulate the logic of a real algo. \n",
        "        testset['predictions-random-' + label] = random_clf.predict(X_test)\n",
        "\n",
        "        # Majority Classifier\n",
        "        majority_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "        majority_clf.fit(X_train, y_train)# it is uselless X stimulate the logic of a real algo. \n",
        "        testset['predictions-majority-' + label] = majority_clf.predict(X_test)\n",
        "\n",
        "        # Compute F1 scores\n",
        "        random_f1 = f1_score(y_test, testset['predictions-random-' + label], average='macro', zero_division=0)\n",
        "        majority_f1 = f1_score(y_test, testset['predictions-majority-' + label], average='macro', zero_division=0)\n",
        "\n",
        "        print(f\"F1 Score for Random Classifier ({label}): {random_f1:.3f}\")\n",
        "        print(f\"F1 Score for Majority Classifier ({label}): {majority_f1:.3f}\")\n",
        "\n",
        "        # Generate and save classification reports\n",
        "        os.makedirs('reports/random', exist_ok=True)\n",
        "        os.makedirs('reports/majority', exist_ok=True)\n",
        "\n",
        "        random_report = classification_report(y_test, testset['predictions-random-' + label], zero_division=0)\n",
        "        majority_report = classification_report(y_test, testset['predictions-majority-' + label], zero_division=0)\n",
        "\n",
        "        with open(f'reports/random/random_classifier_report_{label}.txt', 'w') as random_file:\n",
        "            random_file.write(f\"Classification Report for Random Classifier ({label}):\\n\")\n",
        "            random_file.write(random_report)\n",
        "\n",
        "        with open(f'reports/majority/majority_classifier_report_{label}.txt', 'w') as majority_file:\n",
        "            majority_file.write(f\"Classification Report for Majority Classifier ({label}):\\n\")\n",
        "            majority_file.write(majority_report)\n",
        "        \n",
        "        \n",
        "    \n",
        "    # Custom metric score calculation\n",
        "    def compute_score(hazards_true, products_true, hazards_pred, products_pred):\n",
        "        \"\"\"\n",
        "        Custom scoring function to compute the macro F1 score for hazards and products.\n",
        "        \n",
        "        Args:\n",
        "            hazards_true: Ground truth labels for hazards.\n",
        "            products_true: Ground truth labels for products.\n",
        "            hazards_pred: Predicted labels for hazards.\n",
        "            products_pred: Predicted labels for products.\n",
        "        \n",
        "        Returns:\n",
        "            A float representing the combined macro F1 score.\n",
        "        \"\"\"\n",
        "        f1_hazards = f1_score(hazards_true, hazards_pred, average='macro', zero_division=0)\n",
        "        f1_products = f1_score(\n",
        "            products_true[hazards_pred == hazards_true],\n",
        "            products_pred[hazards_pred == hazards_true],\n",
        "            average='macro', \n",
        "            zero_division=0\n",
        "        )\n",
        "        return (f1_hazards + f1_products) / 2.\n",
        "\n",
        "    # Example of calculating scores for Sub-Tasks (if needed):\n",
        "    # Uncomment the following lines to compute scores for tasks\n",
        "    print(f\"Score Sub-Task 1 - Random Classifier: {compute_score(testset['hazard-category'], testset['product-category'], testset['predictions-random-hazard-category'], testset['predictions-random-product-category']):.3f}\")\n",
        "    print(f\"Score Sub-Task 2 - Random Classifier: {compute_score(testset['hazard'], testset['product'], testset['predictions-random-hazard'], testset['predictions-random-product-category']):.3f}\")\n",
        "    print(f\"Score Sub-Task 1 - Majority Classifier: {compute_score(testset['hazard-category'], testset['product-category'], testset['predictions-majority-hazard-category'], testset['predictions-majority-product-category']):.3f}\")\n",
        "    print(f\"Score Sub-Task 2 - Majority Classifier: {compute_score(testset['hazard'], testset['product'], testset['predictions-majority-hazard'], testset['predictions-majority-product']):.3f}\")\n",
        "\n",
        "# Call the function with the required dataframe (e.g., df_augmented or any other dataframe)\n",
        "evaluate_baselines(df_augmented, feature_column='text', stratify_column='hazard-category')\n",
        "# Uncomment the following line to use a different feature column\n",
        "# evaluate_baselines(df_augmented, feature_column='title', stratify_column='hazard-category')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Results and Observations\n",
        "- Label: `hazard-category`\n",
        "    - Random Classifier F1: 0.076\n",
        "    - Majority Classifier F1: 0.047\n",
        "- Performance is slightly better for the Random Classifier, but both are low, indicating the dataset is likely imbalanced, and random guessing doesn't align well with true labels.\n",
        "\n",
        "- Label: `product-category`\n",
        "    - Random Classifier F1: 0.034\n",
        "    - Majority Classifier F1: 0.019\n",
        "- Performance drops further here. It suggests more complexity or higher imbalance in this label.\n",
        "\n",
        "- Label: `hazard`\n",
        "    - Random Classifier F1: 0.005\n",
        "    - Majority Classifier F1: 0.001\n",
        "    - Both scores are extremely low, possibly due to:\n",
        "        - Large number of classes.\n",
        "        - Sparse distribution of classes.\n",
        "        - Poor representation of these classes in the Random Classifier's uniform predictions or Majority Classifier's mode.\n",
        "\n",
        "- Label: `product`\n",
        "    - Random Classifier F1: 0.000\n",
        "    - Majority Classifier F1: 0.000\n",
        "    - Both classifiers completely fail to capture meaningful patterns for this label. This could suggest extreme imbalance or lack of meaningful correlation in the dataset.\n",
        "\n",
        "- Sub-Tasks\n",
        "    - Score Sub-Task 1: hazard-category & product-category\n",
        "        - Random Classifier Score: 0.057\n",
        "        - Majority Classifier Score: 0.031\n",
        "        - Indicates the overall performance when combining macro F1 scores for hazard-category and product-category. Random guessing outperforms predicting the most frequent class, but both are weak.\n",
        "    - Score Sub-Task 2: hazard & product\n",
        "        - Random Classifier Score: 0.003\n",
        "        - Majority Classifier Score: 0.001\n",
        "        - Reflects the severe challenge for these labels. The performance is near zero, affirming the labels require more sophisticated approaches.\n",
        "\n",
        "-  `Conclusions` : \n",
        "- Baseline as a Benchmark:\n",
        "\n",
        "    - **The poor F1 scores highlight the challenging nature of the task and dataset**.\n",
        "    - These results provide a benchmark to evaluate future models. Any model achieving significantly higher F1 scores would demonstrate effective learning.\n",
        "\n",
        "- Dataset Imbalance:\n",
        "\n",
        "    - The low performance of the Majority Classifier indicates severe class imbalance across all labels.\n",
        "    - Future models should address this using strategies like stratified sampling, oversampling, or weighted loss functions.\n",
        "\n",
        "- Complexity of Labels:\n",
        "\n",
        "    - The complexity increases from hazard-category and product-category to hazard and product, as reflected in the declining F1 scores.\n",
        "\n",
        "- Actionable Insights:\n",
        "\n",
        "    - Preprocessing: Investigate the class distributions and apply balancing techniques.\n",
        "    - Feature Engineering: Consider enhancing the feature column (e.g., using embeddings).\n",
        "    - Advanced Models: Apply models capable of handling imbalance, such as tree-based methods, ensemble models, or neural networks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Traditional and Advanced Approach - Design Decision (skeleton of function) and Limitations in Implemeentation (Resourses) \n",
        "\n",
        "- For the traditional ML approach we will run `Logistic regression` and for advanced algorythm `X-Boost` \n",
        "- This is because these approaches reflect diffrent things. \n",
        "    - `Logistic Regression`:  serves as a simple, interpretable way for understanding how well your data can be modeled with `linear relationships`.\n",
        "    - `X-Boost`: if XGBoost significantly outperforms logistic regression, it suggests that your data has complex patterns that require `non-linear modeling`.\n",
        "\n",
        "-  Skeleton Function, we spent time on writting a \"skeletton\" of function in order to be easy adaptable if we will change the model. Both for logistic regression and x-boost we have the following logic in code : \n",
        "    1. <br> split train test stratisfy \n",
        "    2. <br> one vs all \n",
        "    3. <br> opttuna C regularization  cross - vall \n",
        "    4. <br> tf-idf pipeline \n",
        "    5. <br>\n",
        "    6. <br>\n",
        "\n",
        "Key Note : Due to time - space limitations we  Hyperparameter tuning \n",
        "\n",
        "- Limitations \n",
        "    1. SMOTE <br>\n",
        "    2. CROSS VAL <br>\n",
        "    3. <br>\n",
        "    4. <br>\n",
        "    5. <br>\n",
        "    6. <br> \n",
        "- Optuna k-0fold\n",
        "\n",
        "sklearn  not gpu usage \n",
        "\n",
        "logistic not svm due to resource more complex \n",
        "\n",
        "smote xoros ayjanei "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def evaluate_log_regression_with_ova(dataframe, feature_column, testset_competition):\n",
        "    \"\"\"\n",
        "    Function to evaluate one-vs-all logistic regression classifier on a given dataframe\n",
        "    without applying SMOTE.\n",
        "\n",
        "    Args:\n",
        "        dataframe: The input dataframe containing the dataset.\n",
        "        feature_column: The name of the column in the dataframe to be used as features.\n",
        "        test_competition: The unlabeled dataframe \n",
        "    \"\"\"\n",
        "    np.random.seed(42)  # For reproducibility\n",
        "\n",
        "    # Dictionary to store predictions for each label\n",
        "    predictions_dict = {}\n",
        "\n",
        "    # Define the pipeline\n",
        "    text_clf_lr = Pipeline([\n",
        "        ('vect', TfidfVectorizer(strip_accents='unicode', analyzer='char', ngram_range=(2, 5), max_df=0.5, min_df=5)),\n",
        "        ('clf', LogisticRegression(max_iter=1000, random_state=2024))\n",
        "    ])\n",
        "\n",
        "    for label in ('hazard-category', 'product-category', 'hazard', 'product'):\n",
        "        print(f\"Evaluating for label: {label}\")\n",
        "\n",
        "        # Train-test split with stratification based on the current label\n",
        "        trainset, testset = train_test_split(\n",
        "            dataframe,\n",
        "            test_size=0.2,\n",
        "            random_state=2024,\n",
        "            stratify=dataframe[label]\n",
        "        )\n",
        "\n",
        "        # Extract train and test features\n",
        "        X_train = trainset[feature_column]\n",
        "        X_test = testset[feature_column]\n",
        "\n",
        "        # Target\n",
        "        y_train = trainset[label]\n",
        "        y_test = testset[label]\n",
        "\n",
        "        # Logistic Regression Classifier with OvA using OneVsRestClassifier\n",
        "        logreg_clf = OneVsRestClassifier(text_clf_lr)\n",
        "        logreg_clf.fit(X_train, y_train)\n",
        "        predictions = logreg_clf.predict(X_test)\n",
        "\n",
        "        # Store predictions separately\n",
        "        predictions_dict[label] = {\n",
        "            \"y_test\": y_test,\n",
        "            \"predictions\": predictions\n",
        "        }\n",
        "\n",
        "        # Predict unlabelled data **************************************************\n",
        "        testset_competition[label] = logreg_clf.predict(testset_competition['title'])\n",
        "\n",
        "        # Compute F1 scores\n",
        "        logreg_f1 = f1_score(y_test, predictions, average='macro', zero_division=0)\n",
        "        print(f\"F1 Score for Logistic Regression Classifier ({label}): {logreg_f1:.3f}\")\n",
        "\n",
        "        # Generate and save classification reports\n",
        "        os.makedirs('reports/logreg', exist_ok=True)\n",
        "\n",
        "        logreg_report = classification_report(y_test, predictions, zero_division=0)\n",
        "\n",
        "        with open(f'reports/logreg/logreg_classifier_report_{label}.txt', 'w') as logreg_file:\n",
        "            logreg_file.write(f\"Classification Report for Logistic Regression Classifier ({label}):\\n\")\n",
        "            logreg_file.write(logreg_report)\n",
        "            logreg_file.write(f\"F1 Score for Logistic Regression Classifier ({label}): {logreg_f1:.3f}\")\n",
        "\n",
        "    # Custom metric score calculation\n",
        "    def compute_score(hazards_true, products_true, hazards_pred, products_pred):\n",
        "        \"\"\"\n",
        "        Custom scoring function to compute the macro F1 score for hazards and products.\n",
        "\n",
        "        Args:\n",
        "            hazards_true: Ground truth labels for hazards.\n",
        "            products_true: Ground truth labels for products.\n",
        "            hazards_pred: Predicted labels for hazards.\n",
        "            products_pred: Predicted labels for products.\n",
        "\n",
        "        Returns:\n",
        "            A float representing the combined macro F1 score.\n",
        "        \"\"\"\n",
        "        f1_hazards = f1_score(hazards_true, hazards_pred, average='macro', zero_division=0)\n",
        "        f1_products = f1_score(\n",
        "            products_true[hazards_pred == hazards_true],\n",
        "            products_pred[hazards_pred == hazards_true],\n",
        "            average='macro',\n",
        "            zero_division=0\n",
        "        )\n",
        "        return (f1_hazards + f1_products) / 2.\n",
        "\n",
        "    # Example of calculating scores for Sub-Tasks (if needed):\n",
        "    print(f\"Score Sub-Task 1 - Logistic Regression Classifier: {compute_score(predictions_dict['hazard-category']['y_test'], predictions_dict['product-category']['y_test'], predictions_dict['hazard-category']['predictions'], predictions_dict['product-category']['predictions']):.3f}\")\n",
        "    print(f\"Score Sub-Task 2 - Logistic Regression Classifier: {compute_score(predictions_dict['hazard']['y_test'], predictions_dict['product']['y_test'], predictions_dict['hazard']['predictions'], predictions_dict['product']['predictions']):.3f}\")\n",
        "\n",
        "    # save predictions to a new folder:\n",
        "    os.makedirs('./submission/logreg/', exist_ok=True)\n",
        "    testset_competition[['hazard-category', 'product-category', 'hazard', 'product']].to_csv('./submission/logreg.csv')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
